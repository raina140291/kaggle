{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages\n",
      "Requirement already satisfied: numpy<=1.14.5,>=1.13.3 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skflow\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/e9/6b78ca459cfa78fdcfaa4c8182840f802c022d7221b5112978034390dae6/skflow-0.1.0.tar.gz\n",
      "Collecting sklearn (from skflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: scipy in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from skflow)\n",
      "Requirement already satisfied: numpy in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from skflow)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\priyanka\\appdata\\local\\amlworkbench\\python\\lib\\site-packages (from sklearn->skflow)\n",
      "Building wheels for collected packages: skflow, sklearn\n",
      "  Running setup.py bdist_wheel for skflow: started\n",
      "  Running setup.py bdist_wheel for skflow: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Priyanka\\AppData\\Local\\pip\\Cache\\wheels\\5b\\2d\\04\\d530e678229357d99cba5bceb7f2df21388072c128fc3e1236\n",
      "  Running setup.py bdist_wheel for sklearn: started\n",
      "  Running setup.py bdist_wheel for sklearn: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Priyanka\\AppData\\Local\\pip\\Cache\\wheels\\76\\03\\bb\\589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built skflow sklearn\n",
      "Installing collected packages: sklearn, skflow\n",
      "Successfully installed skflow-0.1.0 sklearn-0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install skflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Azure Machine Learning data source package\n",
    "from azureml.dataprep import datasource\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, svm, cross_validation, tree, preprocessing, metrics\n",
    "import sklearn.ensemble as ske\n",
    "import tensorflow as tf\n",
    "import skflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          1.0       0.0     3.0   \n",
       "1          2.0       1.0     1.0   \n",
       "2          3.0       1.0     3.0   \n",
       "3          4.0       1.0     1.0   \n",
       "4          5.0       0.0     3.0   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0    1.0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0    0.0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0    1.0   \n",
       "4                           Allen, Mr. William Henry    male  35.0    0.0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0    0.0         A/5 21171   7.2500              S  \n",
       "1    0.0          PC 17599  71.2833   C85        C  \n",
       "2    0.0  STON/O2. 3101282   7.9250              S  \n",
       "3    0.0            113803  53.1000  C123        S  \n",
       "4    0.0            373450   8.0500              S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = datasource.load_datasource('train.dsource')\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column heading variables have the following meanings:\n",
    "\n",
    "    survival: Survival (0 = no; 1 = yes)\n",
    "    class: Passenger class (1 = first; 2 = second; 3 = third)\n",
    "    name: Name\n",
    "    sex: Sex\n",
    "    age: Age\n",
    "    sibsp: Number of siblings/spouses aboard\n",
    "    parch: Number of parents/children aboard\n",
    "    ticket: Ticket number\n",
    "    fare: Passenger fare\n",
    "    cabin: Cabin\n",
    "    embarked: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "    boat: Lifeboat (if survived)\n",
    "    body: Body number (if did not survive and body was recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data in a dataframe, we can begin an advanced analysis of the data using powerful single-line Pandas functions. First, let’s examine the overall chance of survival for a Titanic passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3838383838383838"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation shows that only 38% of the passengers survived. Not the best odds. The reason for this massive loss of life is that the Titanic was only carrying 20 lifeboats, which was not nearly enough for the 1,317 passengers and 885 crew members aboard. It seems unlikely that all of the passengers would have had equal chances at survival, so we will continue breaking down the data to examine the social dynamics that determined who got a place on a lifeboat and who did not.\n",
    "\n",
    "Social classes were heavily stratified in the early twentieth century. This was especially true on the Titanic, where the luxurious first-class areas were completely off limits to the middle-class passengers in second class, and especially to those who carried a third class “economy price” ticket. To get a view into the composition of each class, we can group data by class, and view the averages for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>461.597222</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.356481</td>\n",
       "      <td>84.154687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>445.956522</td>\n",
       "      <td>0.472826</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>20.662183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>439.154786</td>\n",
       "      <td>0.242363</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>0.615071</td>\n",
       "      <td>0.393075</td>\n",
       "      <td>13.675550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId  Survived        Age     SibSp     Parch       Fare\n",
       "Pclass                                                                 \n",
       "1.0      461.597222  0.629630  38.233441  0.416667  0.356481  84.154687\n",
       "2.0      445.956522  0.472826  29.877630  0.402174  0.380435  20.662183\n",
       "3.0      439.154786  0.242363  25.140620  0.615071  0.393075  13.675550"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby('Pclass').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start drawing some interesting insights from this data. For instance, passengers in first class had a 62% chance of survival, compared to a 25.5% chance for those in 3rd class. Additionally, the lower classes generally consisted of younger people, and the ticket prices for first class were predictably much higher than those for second and third class. The average ticket price for first class (£87.5) is equivalent to $13,487 in 2016.\n",
    "\n",
    "We can extend our statistical breakdown using the grouping function for both class and sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>female</th>\n",
       "      <td>469.212766</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>34.611765</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>106.125798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>455.729508</td>\n",
       "      <td>0.368852</td>\n",
       "      <td>41.281386</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>67.226127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2.0</th>\n",
       "      <th>female</th>\n",
       "      <td>443.105263</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>28.722973</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>21.970121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>447.962963</td>\n",
       "      <td>0.157407</td>\n",
       "      <td>30.740707</td>\n",
       "      <td>0.342593</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>19.741782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3.0</th>\n",
       "      <th>female</th>\n",
       "      <td>399.729167</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>16.118810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>455.515850</td>\n",
       "      <td>0.135447</td>\n",
       "      <td>26.507589</td>\n",
       "      <td>0.498559</td>\n",
       "      <td>0.224784</td>\n",
       "      <td>12.661633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PassengerId  Survived        Age     SibSp     Parch  \\\n",
       "Pclass Sex                                                            \n",
       "1.0    female   469.212766  0.968085  34.611765  0.553191  0.457447   \n",
       "       male     455.729508  0.368852  41.281386  0.311475  0.278689   \n",
       "2.0    female   443.105263  0.921053  28.722973  0.486842  0.605263   \n",
       "       male     447.962963  0.157407  30.740707  0.342593  0.222222   \n",
       "3.0    female   399.729167  0.500000  21.750000  0.895833  0.798611   \n",
       "       male     455.515850  0.135447  26.507589  0.498559  0.224784   \n",
       "\n",
       "                     Fare  \n",
       "Pclass Sex                 \n",
       "1.0    female  106.125798  \n",
       "       male     67.226127  \n",
       "2.0    female   21.970121  \n",
       "       male     19.741782  \n",
       "3.0    female   16.118810  \n",
       "       male     12.661633  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_sex_grouping = titanic_df.groupby(['Pclass','Sex']).mean()\n",
    "class_sex_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4b219aa58>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a4b2044c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_sex_grouping['Survived'].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the Titanic was sinking, the officers famously prioritized who was allowed in a lifeboat with the strict maritime tradition of evacuating women and children first. Our statistical results clearly reflect the first part of this policy as, across all classes, women were much more likely to survive than the men. We can also see that the women were younger than the men on average, were more likely to be traveling with family, and paid slightly more for their tickets.\n",
    "\n",
    "The effectiveness of the second part of this “Women and children first” policy can be deduced by breaking down the survival rate by age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4b544ecf8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a4b544e550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_by_age = pd.cut(titanic_df[\"Age\"], np.arange(0, 90, 10))\n",
    "age_grouping = titanic_df.groupby(group_by_age).mean()\n",
    "age_grouping['Survived'].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that children were indeed the most likely age group to survive, although this percentage was still tragically below 60%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we perform a count of each column, we will see that much of the data on certain fields is missing. Most machine learning algorithms will have a difficult time handling missing values, so we will need to make sure that each row has a value for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          891\n",
       "Embarked       891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    714\n",
       "Survived       714\n",
       "Pclass         714\n",
       "Name           714\n",
       "Sex            714\n",
       "Age            714\n",
       "SibSp          714\n",
       "Parch          714\n",
       "Ticket         714\n",
       "Fare           714\n",
       "Cabin          714\n",
       "Embarked       714\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.count() \n",
    "#Probably requires the age to be filled in using the previous notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to format the remaining data in a way that our machine learning algorithms will accept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_titanic_df(df):\n",
    "    processed_df = df.copy()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    processed_df.Sex = le.fit_transform(processed_df.Sex)\n",
    "    processed_df.Embarked = le.fit_transform(processed_df.Embarked)\n",
    "    processed_df = processed_df.drop(['Name','Ticket','Cabin'],axis=1)\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = preprocess_titanic_df(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    float64\n",
       "Survived       float64\n",
       "Pclass         float64\n",
       "Sex              int64\n",
       "Age            float64\n",
       "SibSp          float64\n",
       "Parch          float64\n",
       "Fare           float64\n",
       "Embarked         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The “sex” and “embarked” fields are both string values that correspond to categories (i.e “Male” and “Female”) so we will run each through a preprocessor. This preprocessor will convert these strings into integer keys, making it easier for the classification algorithms to find patterns. For instance, “Female” and “Male” will be converted to 0 and 1 respectively. The “name”, “ticket”, \"Cabin\" columns consist of non-categorical string values. These are difficult to use in a classification algorithm, so we will drop them from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_df.drop(['Survived'], axis=1).values\n",
    "y = processed_df['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we separate the data set into two arrays: “X” containing all of the values for each row besides “survived”, and “y” containing only the “survived” value for that row. The classification algorithms will compare the attribute values of “X” to the corresponding values of “y” to detect patterns in how different attributes values tend to affect the survival of a passenger.\n",
    "\n",
    "Finally, we break the “X” and “y” array into two parts each — a training set and a testing set. We will feed the training set into the classification algorithm to form a trained model. Once the model is formed, we will use it to classify the testing set, allowing us to determine the accuracy of the model. Here we have have made a 20/80 split, such that 80% of the dataset will be used for training and 20% will be used for testing.\n",
    "\n",
    "We will start off with a simple decision tree classifier. A decision tree examines one variable at a time, and splits into one of two branches based on the result of that value, at which point it does the same for the next variable. \n",
    "\n",
    "The tree first splits by sex, and then by class, since it has learned during the training phase that these are the two most important features for determining survival. The dark blue boxes indicate passengers who are likely to survive, and the dark orange boxes represent passengers who are almost certainly doomed. Interestingly, after splitting by class, the main deciding factor determining the survival of women is the ticket fare that they paid, while the deciding factor for men is their age (with children being much more likely to survive).\n",
    "\n",
    "To create this tree, we first initialize an instance of an untrained decision tree classifier. (Here we will set the maximum depth of the tree to 10). Next we “fit” this classifier to our training set, enabling it to learn about how different factors affect the survivability of a passenger. Now that the decision tree is ready, we can “score” it using our test data to determine how accurate it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = tree.DecisionTreeClassifier(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7202797202797203"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt.fit (X_train, y_train)\n",
    "clf_dt.score (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting reading, 0.7703, means that the model correctly predicted the survival of 77% of the test set. Not bad for our first model!\n",
    "\n",
    "If you are being an attentive, skeptical reader (as you should be), you might be thinking that the accuracy of the model could vary depending on which rows were selected for the training and test sets. We will get around this problem by using a shuffle validator.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_validator = cross_validation.ShuffleSplit(len(X), n_iter=20, test_size=0.2, random_state=0)\n",
    "def test_classifier(clf):\n",
    "    scores = cross_validation.cross_val_score(clf, X, y, cv=shuffle_validator)\n",
    "    print(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7636 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "test_classifier(clf_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shuffle validator applies the same random 20:80 split as before, but this time it generates 20 unique permutations of this split. By passing this shuffle validator as a parameter to the “cross_val_score” function, we can score our classifier against each of the different splits, and compute the average accuracy and standard deviation from the results.\n",
    "\n",
    "The result shows that our decision tree classifier has an overall accuracy of 77.34%, although it can go up to 80% and down to 75% depending on the training/test split. Using scikit-learn, we can easily test other machine learning algorithms using the exact same syntax. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The “Random Forest” classification algorithm will create a multitude of (generally very poor) trees for the data set using different random subsets of the input variables, and will return whichever prediction was returned by the most trees. This helps to avoid “overfitting”, a problem that occurs when a model is so tightly fitted to arbitrary correlations in the training data that it performs poorly on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8105 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "clf_rf = ske.RandomForestClassifier(n_estimators=50)\n",
    "test_classifier(clf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harper, Mrs. Henry Sleeper (Myna Haxtun)</td>\n",
       "      <td>female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17572</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>D33</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Greenfield, Mr. William Bertram</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17759</td>\n",
       "      <td>63.3583</td>\n",
       "      <td>D10 D12</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Turpin, Mrs. William John Robert (Dorothy Ann ...</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11668</td>\n",
       "      <td>21.0000</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Vander Planke, Miss. Augusta Maria</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345764</td>\n",
       "      <td>18.0000</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Nicola-Yarred, Miss. Jamila</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2651</td>\n",
       "      <td>11.2417</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Arnold-Franchi, Mrs. Josef (Josefine Franchi)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349237</td>\n",
       "      <td>17.8000</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "23         24.0       1.0     1.0   \n",
       "52         53.0       1.0     1.0   \n",
       "97         98.0       1.0     1.0   \n",
       "21         22.0       1.0     2.0   \n",
       "41         42.0       0.0     2.0   \n",
       "14         15.0       0.0     3.0   \n",
       "18         19.0       0.0     3.0   \n",
       "25         26.0       1.0     3.0   \n",
       "38         39.0       0.0     3.0   \n",
       "39         40.0       1.0     3.0   \n",
       "49         50.0       0.0     3.0   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "23                       Sloper, Mr. William Thompson    male  28.0    0.0   \n",
       "52           Harper, Mrs. Henry Sleeper (Myna Haxtun)  female  49.0    1.0   \n",
       "97                    Greenfield, Mr. William Bertram    male  23.0    0.0   \n",
       "21                              Beesley, Mr. Lawrence    male  34.0    0.0   \n",
       "41  Turpin, Mrs. William John Robert (Dorothy Ann ...  female  27.0    1.0   \n",
       "14               Vestrom, Miss. Hulda Amanda Adolfina  female  14.0    0.0   \n",
       "18  Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0    1.0   \n",
       "25  Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0    1.0   \n",
       "38                 Vander Planke, Miss. Augusta Maria  female  18.0    2.0   \n",
       "39                        Nicola-Yarred, Miss. Jamila  female  14.0    1.0   \n",
       "49      Arnold-Franchi, Mrs. Josef (Josefine Franchi)  female  18.0    1.0   \n",
       "\n",
       "    Parch    Ticket     Fare    Cabin Embarked  \n",
       "23    0.0    113788  35.5000       A6        S  \n",
       "52    0.0  PC 17572  76.7292      D33        C  \n",
       "97    1.0  PC 17759  63.3583  D10 D12        C  \n",
       "21    0.0    248698  13.0000      D56        S  \n",
       "41    0.0     11668  21.0000                 S  \n",
       "14    0.0    350406   7.8542                 S  \n",
       "18    0.0    345763  18.0000                 S  \n",
       "25    5.0    347077  31.3875                 S  \n",
       "38    0.0    345764  18.0000                 S  \n",
       "39    0.0      2651  11.2417                 C  \n",
       "49    0.0    349237  17.8000                 S  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.fit (X_train, y_train)\n",
    "clf_rf.score (X_test, y_test)\n",
    "prediction = clf_rf.predict(X_test)\n",
    "passenger_set[passenger_set.Survived != prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "***FIND OUT ABOUT THE PEOPLE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The “Gradient Boosting” classifier will generate many weak, shallow prediction trees and will combine, or “boost”, them into a strong model. This model performs very well on our data set, but has the drawback of being relatively slow and difficult to optimize, as the model construction happens sequentially so it cannot be parallelized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8143 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "clf_gb = ske.GradientBoostingClassifier(n_estimators=50)\n",
    "test_classifier(clf_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A “Voting” classifier can be used to apply multiple conceptually divergent classification models to the same data set and will return the majority vote from all of the classifiers. For instance, if the gradient boosting classifier predicts that a passenger will not survive, but the decision tree and random forest classifiers predict that they will live, the voting classifier will chose the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\sklearn\\preprocessing\\label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8122 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "eclf = ske.VotingClassifier([('dt', clf_dt), ('rf', clf_rf), ('gb', clf_gb)])\n",
    "test_classifier(eclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computational Brains — An Introduction to Deep Neural Networks\n",
    "\n",
    "Neural networks are a rapidly developing paradigm for information processing based loosely on how neurons in the brain processes information. A neural network consists of multiple layers of nodes, where each node performs a unit of computation and passes the result onto the next node. Multiple nodes can pass inputs to a single node and vice versa.\n",
    "\n",
    "The neural network also contains a set of weights, which can be refined over time as the network learns from sample data. The weights are used to describe and refine the connection strengths between nodes. For instance, in our Titanic data set, node connections transmitting the passenger sex and class will likely be weighted very heavily, since these are important for determining the survival of a passenger.  \n",
    "\n",
    "By Glosser.ca, CC BY-SA 3.0, source: https://commons.wikimedia.org/w/index.php?curid=24913461\n",
    "\n",
    "A Deep Neural Network (DNN) is a neural network that works not just by passing data between nodes, but by passing data between layers of nodes. Each layer of nodes is able to aggregate and recombine the outputs from the previous layer, allowing the network to gradually piece together and make sense of unstructured data (such as an image). Such networks can also be heavily optimized due to their modular nature, allowing the operations of each node layer to be parallelized en masse across multiple CPUs and even GPUs.\n",
    "\n",
    "We have barely begun to skim the surface of explaining neural networks. For a more in depth explanation of the inner workings of DNNs, this is a good resource: http://deeplearning4j.org/neuralnet-overview.html.\n",
    "\n",
    "This awesome tool allows you to visualize and modify an active deep neural network: http://playground.tensorflow.org.\n",
    "\n",
    "The major advantage of neural networks over traditional machine learning techniques is their ability to find patterns in unstructured data (such as images or natural language). Training a deep neural network on the Titanic data set is total overkill, but it’s a cool technology to work with, so we’re going to do it anyway.\n",
    "\n",
    "An emerging powerhouse in programing neural networks is an open source library from Google called TensorFlow. This library is the foundation for many of the most recent advances in machine learning, such as being used to train computer programs to create unique works of music and visual art (https://magenta.tensorflow.org/welcome-to-magenta). The syntax for using TensorFlow is somewhat abstract, but there is a wrappercalled “skflow” in the TensorFlow package that allows us to build deep neural networks using the now-familiar scikit-learn syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-52-cb2365d26750>:3: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "WARNING:tensorflow:From C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:142: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "WARNING:tensorflow:From C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please convert numpy dtypes explicitly.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:182: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please specify feature columns explicitly.\n",
      "WARNING:tensorflow:From C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1179: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Priyanka\\AppData\\Local\\Temp\\tmpwxq62jr2\n",
      "INFO:tensorflow:Using config: {'_is_chief': True, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001A4B55704A8>, '_save_summary_steps': 100, '_train_distribute': None, '_keep_checkpoint_max': 5, '_model_dir': 'C:\\\\Users\\\\Priyanka\\\\AppData\\\\Local\\\\Temp\\\\tmpwxq62jr2', '_num_ps_replicas': 0, '_master': '', '_num_worker_replicas': 0, '_session_config': None, '_device_fn': None, '_save_checkpoints_steps': None, '_environment': 'local', '_task_type': None, '_task_id': 0, '_tf_random_seed': None}\n",
      "WARNING:tensorflow:From <ipython-input-52-cb2365d26750>:5: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-52-cb2365d26750>:5: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-52-cb2365d26750>:5: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:508: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to the Estimator interface.\n",
      "WARNING:tensorflow:From C:\\Users\\Priyanka\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Labels dtype should be integer Instead got <dtype: 'float64'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-cb2365d26750>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfeature_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_real_valued_columns_from_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDNNClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0msurvived_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurvived_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 instructions)\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[0m_verify_input_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m       \u001b[0mSKCompat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, steps, max_steps, monitors)\u001b[0m\n\u001b[0;32m   1525\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m         monitors=all_monitors)\n\u001b[0m\u001b[0;32m   1528\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 instructions)\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[0;32m    522\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks)\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m       \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_or_create_global_step_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m       \u001b[0mmodel_fn_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_train_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLOSSES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m       \u001b[0mall_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_get_train_ops\u001b[1;34m(self, features, labels)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mModelFnOps\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \"\"\"\n\u001b[1;32m-> 1264\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_eval_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, metrics, config)\u001b[0m\n\u001b[0;32m   1225\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'model_dir'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_dir'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelFnOps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[1;34m(features, labels, mode, params, config)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mtrain_op_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_train_op_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         logits=logits)\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py\u001b[0m in \u001b[0;36mcreate_model_fn_ops\u001b[1;34m(self, features, mode, labels, train_op_fn, logits, logits_input, scope)\u001b[0m\n\u001b[0;32m   1083\u001b[0m           \u001b[0mhead_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m           \u001b[0mweight_column_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_column_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m           enable_centered_bias=self._enable_centered_bias)\n\u001b[0m\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_transform_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py\u001b[0m in \u001b[0;36m_create_model_fn_ops\u001b[1;34m(features, mode, loss_fn, logits_to_predictions_fn, metrics_fn, create_output_alternatives_fn, labels, train_op_fn, logits, logits_dimension, head_name, weight_column_name, enable_centered_bias)\u001b[0m\n\u001b[0;32m    655\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINFER\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[0mweight_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_weight_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_column_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweighted_average_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m     \u001b[1;31m# The name_scope escapism is needed to maintain the same summary tag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;31m# after switching away from the now unsupported API.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py\u001b[0m in \u001b[0;36m_wrapped_loss_fn\u001b[1;34m(self, labels, logits, weights)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_wrapped_loss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_logits_to_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py\u001b[0m in \u001b[0;36m_softmax_cross_entropy_loss\u001b[1;34m(labels, logits, weights)\u001b[0m\n\u001b[0;32m    969\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m       raise ValueError(\"Labels dtype should be integer \"\n\u001b[1;32m--> 971\u001b[1;33m                        \"Instead got %s.\" % labels.dtype)\n\u001b[0m\u001b[0;32m    972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m     \u001b[1;31m# sparse_softmax_cross_entropy_with_logits requires [batch_size] labels.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Labels dtype should be integer Instead got <dtype: 'float64'>."
     ]
    }
   ],
   "source": [
    "# Deep Neural Network\n",
    "feature_columns = tensorflow.contrib.learn.infer_real_valued_columns_from_input(processed_df)\n",
    "classifier = tensorflow.contrib.learn.DNNClassifier(hidden_units=[10, 20, 10], n_classes=3, feature_columns=feature_columns)\n",
    "classifier.fit(X_train, y_train, steps=300, batch_size=32)\n",
    "survived_predictions = list(classifier.predict(X, as_iterable=True))\n",
    "score = metrics.accuracy_score(y, survived_predictions)\n",
    "print('Accuracy: %f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model(X, y):\n",
    "    layers = skflow.ops.dnn(X, [20, 40, 20], tf.tanh)\n",
    "    return skflow.models.logistic_regression(layers, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the increased power and lengthier runtime of these neural network models, you will notice that the accuracy is still about the same as what we achieved using more traditional tree-based methods. The main advantage of neural networks — unsupervised learning of unstructured data — doesn’t necessarily lend itself well to our Titanic dataset, so this is not too surprising.  \n",
    "\n",
    "I still, however, think that running the passenger data of a 104-year-old shipwreck through a cutting-edge deep neural network is pretty cool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the accuracy for all of our models is maxing out around 80%, it will be interesting to look at specific passengers for whom these classification algorithms are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers_set_1 = titanic_df[titanic_df.Pclass == 1].iloc[:20,:].copy()\n",
    "passengers_set_2 = titanic_df[titanic_df.Pclass == 2].iloc[:20,:].copy()\n",
    "passengers_set_3 = titanic_df[titanic_df.Pclass == 3].iloc[:20,:].copy()\n",
    "passenger_set = pd.concat([passengers_set_1,passengers_set_2,passengers_set_3])\n",
    "testing_set = preprocess_titanic_df(passenger_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.concat([titanic_df, passenger_set]).drop_duplicates(keep=False)\n",
    "training_set = preprocess_titanic_df(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_set.drop(['Survived'], axis=1).values\n",
    "y_train = training_set['Survived'].values\n",
    "X_test = testing_set.drop(['Survived'], axis=1).values\n",
    "y_test = testing_set['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classification local",
   "language": "python",
   "name": "classification_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
