{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Azure Machine Learning data source package\n",
    "from azureml.dataprep import datasource\n",
    "\n",
    "# classifier models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# modules to handle data\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle provides a test and a train dataset. The training data provides a Survived column which shows a 1 if the passenger survived and a 0 if they did not. This is ultimately the feature we are trying to predict so the test set will not have this column.\n",
    "\n",
    "Because I’m lazy and don’t like doing things twice, I first loaded the data into a train and test variable and then created a titanic variable where I appended the test to the train so that I can create new features to both data sets at the same time. I also created an index for each train and test so that I can separate them out later into their respective train and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Data Wrangling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "train = datasource.load_datasource('train.dsource')\n",
    "test = datasource.load_datasource('test.dsource')\n",
    "\n",
    "# save PassengerId for final submission\n",
    "passengerId = test.PassengerId\n",
    "\n",
    "# merge train and test\n",
    "titanic = train.append(test, ignore_index=True)\n",
    "\n",
    "# create indexes to separate data later on\n",
    "train_idx = len(train)\n",
    "test_idx = len(titanic) - len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0              S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0              S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0              S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris    0.0          1.0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0.0          2.0   \n",
       "2                             Heikkinen, Miss. Laina    0.0          3.0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0.0          4.0   \n",
       "4                           Allen, Mr. William Henry    0.0          5.0   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket  \n",
       "0     3.0    male    1.0       0.0         A/5 21171  \n",
       "1     1.0  female    1.0       1.0          PC 17599  \n",
       "2     3.0  female    0.0       1.0  STON/O2. 3101282  \n",
       "3     1.0  female    1.0       1.0            113803  \n",
       "4     3.0    male    0.0       0.0            373450  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view head of data \n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      "Age            1046 non-null float64\n",
      "Cabin          1309 non-null object\n",
      "Embarked       1309 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null float64\n",
      "PassengerId    1309 non-null float64\n",
      "Pclass         1309 non-null float64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null float64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(7), object(5)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# get info on features\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us all the features (or columns) in the data frame along with the count of non-null values. Looking at the RangeIndex we see that there are 1309 total entries, but the Age, Cabin, Embarked, Fare, and Survived have less than that, suggesting that those columns have some null, or NaN, values. This is a dirty dataset and we either need to drop the rows with NaN values or fill in the gaps by leveraging the data in the dataset to estimate what those values could have been. We will choose the latter and try to estimate those values and fill in the gaps rather than lose observations. However, one thing to note is that the Survived feature will not require us to fill in the gaps as the count of 891 represents the labels from the train data. Remember that we are trying to predict the Survived column and so the test set does not have this column at all.\n",
    "\n",
    "Even though this is technically the “Data Wrangling” section, before we do any data wrangling and address any missing values, I first want to create a Title feature which simply extracts the honorific from the Name feature. Simply put, an honorific is the title or rank of a given person such as “Mrs” or “Miss”. The following code takes a value like “Braund, Mr. Owen Harris” from the Name column and extracts “Mr”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new feature to extract title names from the Name column\n",
    "titanic['Title'] = titanic.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0              S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0              S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0              S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris    0.0          1.0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0.0          2.0   \n",
       "2                             Heikkinen, Miss. Laina    0.0          3.0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0.0          4.0   \n",
       "4                           Allen, Mr. William Henry    0.0          5.0   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket Title  \n",
       "0     3.0    male    1.0       0.0         A/5 21171    Mr  \n",
       "1     1.0  female    1.0       1.0          PC 17599   Mrs  \n",
       "2     3.0  female    0.0       1.0  STON/O2. 3101282  Miss  \n",
       "3     1.0  female    1.0       1.0            113803   Mrs  \n",
       "4     3.0    male    0.0       0.0            373450    Mr  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n",
       "       'Jonkheer', 'Dona'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.Title.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After viewing the unique Titles that were pulled, we see that we have 18 different titles but we will want to normalize these a bit so that we can generalize a bit more. To do this, we will create a dictionary that maps the 18 titles to 6 broader categories and then map that dictionary back to the Title feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr         757\n",
      "Miss       262\n",
      "Mrs        200\n",
      "Master      61\n",
      "Officer     23\n",
      "Royalty      6\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# normalize the titles\n",
    "normalized_titles = {\n",
    "    \"Capt\":       \"Officer\",\n",
    "    \"Col\":        \"Officer\",\n",
    "    \"Major\":      \"Officer\",\n",
    "    \"Jonkheer\":   \"Royalty\",\n",
    "    \"Don\":        \"Royalty\",\n",
    "    \"Sir\" :       \"Royalty\",\n",
    "    \"Dr\":         \"Officer\",\n",
    "    \"Rev\":        \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Dona\":       \"Royalty\",\n",
    "    \"Mme\":        \"Mrs\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Ms\":         \"Mrs\",\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Lady\" :      \"Royalty\"\n",
    "}\n",
    "\n",
    "# map the normalized titles to the current titles \n",
    "titanic.Title = titanic.Title.map(normalized_titles)\n",
    "\n",
    "# view value counts for the normalized titles\n",
    "print(titanic.Title.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason I wanted to create the Title feature first was so that I could use it to estimate the missing ages just a little bit better. The next step is to estimate the missing Age values. To do this, we will group the dataset by Sex, Pclass (Passenger Class), and Title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Pclass  Title  \n",
       "female  1.0     Miss       30.0\n",
       "                Mrs        45.0\n",
       "                Officer    49.0\n",
       "                Royalty    39.0\n",
       "        2.0     Miss       20.0\n",
       "                Mrs        30.0\n",
       "        3.0     Miss       18.0\n",
       "                Mrs        31.0\n",
       "male    1.0     Master      6.0\n",
       "                Mr         41.5\n",
       "                Officer    52.0\n",
       "                Royalty    40.0\n",
       "        2.0     Master      2.0\n",
       "                Mr         30.0\n",
       "                Officer    41.5\n",
       "        3.0     Master      6.0\n",
       "                Mr         26.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by Sex, Pclass, and Title \n",
    "grouped = titanic.groupby(['Sex','Pclass', 'Title'])  \n",
    "\n",
    "# view the median Age by the grouped features \n",
    "grouped.Age.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of simply filling in the missing Age values with the mean or median age of the dataset, by grouping the data by a passenger’s sex, class, and title, we can drill down a bit deeper and get a closer approximation of what a passenger’s age might have been. Using the grouped.Age variable, we can fill in the missing values for Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the grouped median value on the Age NaN\n",
    "titanic.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we move onto the next features with missing values, Cabin, Embarked, and Fare. For these, we wont be doing anything too fancy. We will fill Cabin with “U” for unknown, Embarked we will fill with the most frequent point of embarkment, and since Fare only has 1 missing value we will just fill it in with the median value of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      "Age            1309 non-null float64\n",
      "Cabin          1309 non-null object\n",
      "Embarked       1309 non-null object\n",
      "Fare           1309 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null float64\n",
      "PassengerId    1309 non-null float64\n",
      "Pclass         1309 non-null float64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null float64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "Title          1309 non-null object\n",
      "dtypes: float64(7), object(6)\n",
      "memory usage: 133.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# fill Cabin NaN with U for unknown\n",
    "titanic.Cabin = titanic.Cabin.fillna('U')\n",
    "\n",
    "# find most frequent Embarked value and store in variable\n",
    "most_embarked = titanic.Embarked.value_counts().index[0]\n",
    "\n",
    "# fill NaN with most_embarked value\n",
    "titanic.Embarked = titanic.Embarked.fillna(most_embarked)\n",
    "\n",
    "# fill NaN with median fare\n",
    "titanic.Fare = titanic.Fare.fillna(titanic.Fare.median())\n",
    "\n",
    "# view changes\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good now. As expected, Survived still has missing values but since we are going to eventually be splitting the data back to train and test, we can ignore that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will quickly create two more features before we begin our modeling. The next feature of interest is family size per passenger, since having a larger family may have made it harder to secure a spot on a life boat compared to an individual passenger or a small family trying to get on a life boat. We can leverage the SibSp and Parch features to determine family size since these are a count of sibling/spouse and parent/children respectively per passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of families (including the passenger)\n",
    "titanic['FamilySize'] = titanic.Parch + titanic.SibSp + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last feature we will create will leverage the Cabin feature and simply extract the first letter of the cabin which determines the section where the room would have been. This is potentially relevant since it is possible that some cabins were closer to the life boats and thus those that were closer to them may have had a greater chance at securing a spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>Mr</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>Miss</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0              S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0              S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0              S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris    0.0          1.0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0.0          2.0   \n",
       "2                             Heikkinen, Miss. Laina    0.0          3.0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0.0          4.0   \n",
       "4                           Allen, Mr. William Henry    0.0          5.0   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket Title  FamilySize  \n",
       "0     3.0    male    1.0       0.0         A/5 21171    Mr         2.0  \n",
       "1     1.0  female    1.0       1.0          PC 17599   Mrs         2.0  \n",
       "2     3.0  female    0.0       1.0  STON/O2. 3101282  Miss         1.0  \n",
       "3     1.0  female    1.0       1.0            113803   Mrs         2.0  \n",
       "4     3.0    male    0.0       0.0            373450    Mr         1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step to perform before we can begin our modeling is convert all our categorical features to numbers, as our algorithms can only take an array of numbers as an input, not names or letters. As you noticed from the previous screenshot, we have a few columns to convert. We use the pd.get_dummies() method from Pandas that converts categorical features into dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Pclass_1.0</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_F2</th>\n",
       "      <th>Cabin_F33</th>\n",
       "      <th>Cabin_F38</th>\n",
       "      <th>Cabin_F4</th>\n",
       "      <th>Cabin_G6</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Parch  PassengerId  Sex  SibSp  Survived  FamilySize  \\\n",
       "0  22.0   7.2500    0.0          1.0    0    1.0       0.0         2.0   \n",
       "1  38.0  71.2833    0.0          2.0    1    1.0       1.0         2.0   \n",
       "2  26.0   7.9250    0.0          3.0    1    0.0       1.0         1.0   \n",
       "3  35.0  53.1000    0.0          4.0    1    1.0       1.0         2.0   \n",
       "4  35.0   8.0500    0.0          5.0    0    0.0       0.0         1.0   \n",
       "\n",
       "   Pclass_1.0  Pclass_2.0     ...      Cabin_F2  Cabin_F33  Cabin_F38  \\\n",
       "0           0           0     ...             0          0          0   \n",
       "1           1           0     ...             0          0          0   \n",
       "2           0           0     ...             0          0          0   \n",
       "3           1           0     ...             0          0          0   \n",
       "4           0           0     ...             0          0          0   \n",
       "\n",
       "   Cabin_F4  Cabin_G6  Cabin_T  Embarked_  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0         0        0          0           0           0           1  \n",
       "1         0         0        0          0           1           0           0  \n",
       "2         0         0        0          0           0           0           1  \n",
       "3         0         0        0          0           0           0           1  \n",
       "4         0         0        0          0           0           0           1  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the male and female groups to integer form\n",
    "titanic.Sex = titanic.Sex.map({\"male\": 0, \"female\":1})\n",
    "\n",
    "# create dummy variables for categorical features\n",
    "pclass_dummies = pd.get_dummies(titanic.Pclass, prefix=\"Pclass\")\n",
    "title_dummies = pd.get_dummies(titanic.Title, prefix=\"Title\")\n",
    "cabin_dummies = pd.get_dummies(titanic.Cabin, prefix=\"Cabin\")\n",
    "embarked_dummies = pd.get_dummies(titanic.Embarked, prefix=\"Embarked\")\n",
    "\n",
    "# concatenate dummy columns with main dataset\n",
    "titanic_dummies = pd.concat([titanic, pclass_dummies, title_dummies, cabin_dummies, embarked_dummies], axis=1)\n",
    "\n",
    "# drop categorical fields\n",
    "titanic_dummies.drop(['Pclass', 'Title', 'Cabin', 'Embarked', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "\n",
    "titanic_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>Mr</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>Miss</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0              S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0              S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0              S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris    0.0          1.0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0.0          2.0   \n",
       "2                             Heikkinen, Miss. Laina    0.0          3.0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0.0          4.0   \n",
       "4                           Allen, Mr. William Henry    0.0          5.0   \n",
       "\n",
       "   Pclass  Sex  SibSp  Survived            Ticket Title  FamilySize  \n",
       "0     3.0    0    1.0       0.0         A/5 21171    Mr         2.0  \n",
       "1     1.0    1    1.0       1.0          PC 17599   Mrs         2.0  \n",
       "2     3.0    1    0.0       1.0  STON/O2. 3101282  Miss         1.0  \n",
       "3     1.0    1    1.0       1.0            113803   Mrs         2.0  \n",
       "4     3.0    0    0.0       0.0            373450    Mr         1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Our data is now in the format we need to perform some modeling. Let’s separate it back into train and test data frames using the train_idx and test_idx we created in the beginning of the exercise. We will also separate our training data into X for the predictor variables and y for our response variable which in this case is the Survived labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test data\n",
    "train = titanic_dummies[ :train_idx]\n",
    "test = titanic_dummies[test_idx: ]\n",
    "\n",
    "# convert Survived back to int\n",
    "train.Survived = train.Survived.astype(int)\n",
    "\n",
    "# create X and y for data and target values \n",
    "X = train.drop('Survived', axis=1).values \n",
    "y = train.Survived.values\n",
    "\n",
    "# create array for test set\n",
    "X_test = test.drop('Survived', axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested both a logistic regression model, which is a binary classifier, and a random forrest classifier model which fits a number of decision tree classifiers on the data. I used GridSearchCV to pass in a range of parameters and have it return the best score and the associated parameters.\n",
    "\n",
    "The logistic regression model returned a best score of ~82% while the random forrest model got a best score of ~84% which is the model I ended up using for my predictions. As a result, I will only cover the random forrest model in this section.\n",
    "\n",
    "GridSearchCV needs the estimator argument which in this case is the random forrest model and a param_grid which is a dictionary of parameters for the estimator. To prevent this post from being longer than it needs to be, I will let you look up the documentation for the random forrest classifier to find out what the parameters do.\n",
    "\n",
    "First, I created my dictionary of parameters with different ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create param grid object \n",
    "forrest_params = dict(     \n",
    "    max_depth = [n for n in range(9, 14)],     \n",
    "    min_samples_split = [n for n in range(4, 11)], \n",
    "    min_samples_leaf = [n for n in range(2, 5)],     \n",
    "    n_estimators = [n for n in range(10, 60, 10)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I instantiate the random forrest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Random Forest model\n",
    "forrest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we build the GridSearchCV and fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [9, 10, 11, 12, 13], 'n_estimators': [10, 20, 30, 40, 50], 'min_samples_split': [4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build and fit model \n",
    "forest_cv = GridSearchCV(estimator=forrest, param_grid=forrest_params, cv=6) \n",
    "forest_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this finishes (and it will take quite a few minutes depending on your computer’s speed) you can use the best_score_ and best_estimator_ methods to retrieve the best score and the parameters that led to that score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8383838383838383\n",
      "Optimal params: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=13, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=40, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(forest_cv.best_score_))\n",
    "print(\"Optimal params: {}\".format(forest_cv.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to predict and submit! Remember that we saved the test set under X_test, so we can simply do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forrest prediction on test set\n",
    "forrest_pred = forest_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forrest_pred returns a 418 x 1 array of predictions for the Survived values. In the very first step, I placed the PassengerId column from the original test data into its own variable that I named passengerId. For our final submission, all we have to do is combine the passengerId with forrest_pred into a data frame and output to a csv. The following code does this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with predictions\n",
    "kaggle = pd.DataFrame({'PassengerId': passengerId, 'Survived': forrest_pred})\n",
    "\n",
    "# save to csv\n",
    "kaggle.to_csv('titanic_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classification docker",
   "language": "python",
   "name": "classification_docker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
